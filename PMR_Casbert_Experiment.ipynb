{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f9d29c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Experiment: Composite Annotation Search Using BERT for the PMR\n",
    "- BERT is used to convert compositely annotated entities in biosimulation model repository (PMR) as vectors/embeddings.\n",
    "- A query is converted into vector/embedding using BERT\n",
    "- Calculate the similarity of the query's vector to entity's vectors\n",
    "  - using cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce35b6",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df3cc35-dac3-4f13-a82a-542e69fcb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sentence_transformers import util\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0396b068-4ae4-444d-aa5a-1c849db80fb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2933cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of entity embeddings\n",
    "entityEmbedding = torch.load('casbert_resources/pmr_entities.pt')\n",
    "\n",
    "with open('casbert_resources/pmr_entities.json', 'r') as fp:\n",
    "    entityKeys = json.load(fp)\n",
    "\n",
    "# Dict of predicate embeddings\n",
    "predicateEmbedding = torch.load('casbert_resources/pmr_predicates.pt')\n",
    "\n",
    "# Dict of ontology class embedding\n",
    "ontoEmbedding = torch.load('casbert_resources/pmr_classes.pt')\n",
    "\n",
    "# load ontology dictionaries\n",
    "import gzip, pickle\n",
    "file = gzip.GzipFile('casbert_resources/ontoDf.gz', 'rb')\n",
    "ontologies = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "with open('casbert_resources/pmr_list_of_variable.json', 'r') as fp:\n",
    "    variables = json.load(fp)\n",
    "    \n",
    "# Query Set for test data\n",
    "with open('casbert_resources/pmr_query_test.json', 'r') as fp:\n",
    "    queryTest = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d0d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT model used\n",
    "modelName = 'sentence-transformers/multi-qa-MiniLM-L6-cos-v1'\n",
    "seqLength = 128\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "word_embedding_model = models.Transformer(modelName, max_seq_length=seqLength)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "sbert = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e94ab8",
   "metadata": {},
   "source": [
    "### Performance measure using Mean average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8643a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def averagePrecision(prediction):\n",
    "    if 1 not in prediction:\n",
    "        return 0\n",
    "    tot = 0\n",
    "    for idx, p in enumerate(prediction):\n",
    "        if p>0:\n",
    "            tot += sum(prediction[0:idx+1])/(idx+1)\n",
    "    return tot/sum(prediction)\n",
    "\n",
    "def meanAP(predictions):\n",
    "    tap = 0\n",
    "    stat = {}\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "        ap = averagePrecision(prediction)\n",
    "        stat[idx] = ap\n",
    "        tap += ap\n",
    "    return {'score':tap/len(predictions), 'stat':stat}\n",
    "\n",
    "def meanRR(predictions):\n",
    "    trr = 0\n",
    "    stat = {}\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "        rr = 1/(prediction.index(1)+1) if 1 in prediction else 0\n",
    "        stat[idx] = rr\n",
    "        trr += rr\n",
    "    return {'score':trr/len(predictions), 'stat':stat}\n",
    "\n",
    "def getMAP(queries, searchFunction, indexType=None, pathType=None, topK=10, minSim=0.5):\n",
    "    predictions = []\n",
    "    for query, facts in tqdm(queries.items()):\n",
    "        results = searchFunction(query=query, topK=topK, indexType=indexType, pathType=pathType, minSim=minSim)\n",
    "        predictions += [[1 if varId in facts['vars'] else 0 for varId in results]]\n",
    "    MAP = meanAP(predictions)\n",
    "    return {'MAP':MAP,'MRR':meanRR(predictions)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getMAPs(queries, functions, indexTypes=['class', 'class_predicate'], pathTypes=['single', 'multi'], topK=10, minSim=0.5):\n",
    "    for idx, path in zip(indexTypes, pathTypes):\n",
    "        print(idx, path)\n",
    "    for function in functions:\n",
    "        print(function.__name__)\n",
    "#         print(inspect.getfullargspec(function))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178afd5",
   "metadata": {},
   "source": [
    "### Searching functions\n",
    "Here we prepare several functions with different approah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In some functions, we utilise scispacy to locate phrases or concepts related to a query. \n",
    "# For example a query 'Calcium reverse membrane potential.' \n",
    "# is identified having 2 concepts of 'calcium' and 'reverse membrane potential'\n",
    "# For accurate identification we use 'en_core_sci_scibert' which required GPU for faster performance\n",
    "\n",
    "import en_core_sci_scibert\n",
    "nlp = en_core_sci_scibert.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entitySearch(query, topK=20, indexType='class', pathType=None, minSim=None):\n",
    "    \"\"\"\n",
    "    In this approach:\n",
    "    1. Get vector of query\n",
    "    2. Get similar entities using cosine similarity\n",
    "    3. Return topK result in descending\n",
    "    \"\"\"\n",
    "    textEmbedding = sbert.encode(query, convert_to_tensor=True)\n",
    "    # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "    cosScores = util.pytorch_cos_sim(textEmbedding, entityEmbedding[indexType])[0]\n",
    "    topResults = torch.topk(cosScores, k=topK)\n",
    "    entities = {}\n",
    "    varIds = list(entityKeys.keys())\n",
    "    for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "        entities[varIds[idx]] = [rank, score.item(), entityKeys[varIds[idx]]]\n",
    "    return entities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff3802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OntoEmbedding function\n",
    "\n",
    "classId_List = ontoEmbedding['ClassId']\n",
    "alpha = 0.22\n",
    "\n",
    "# returning text\n",
    "def getClassText(classId, features=['name']):\n",
    "    \"\"\"\n",
    "    features: name, synonym, parent, def\n",
    "    \"\"\"\n",
    "    corpus = {}\n",
    "    if classId in classId_List:\n",
    "        for feature in features:\n",
    "            corpus[feature] = ontologies.loc[classId][feature]\n",
    "    return corpus\n",
    "\n",
    "# returning ontology classes\n",
    "def getClasses(text, feature='name_synonym', topK = 20):\n",
    "    \"\"\"\n",
    "    feature: name, name_synonym, name_synonym_def, name_synonym_def, name_synonym_def_parent\n",
    "    \"\"\"\n",
    "    textEmbedding = sbert.encode(text, convert_to_tensor=True)\n",
    "    # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "    if feature in ontoEmbedding:\n",
    "        cosScores = util.pytorch_cos_sim(textEmbedding, ontoEmbedding[feature])[0]\n",
    "        topResults = torch.topk(cosScores, k=topK)\n",
    "        classes = {}\n",
    "        for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "            classId = classId_List[idx.item()]\n",
    "            classes[classId] = (rank, score.item(), ontologies.loc[classId]['name'])\n",
    "        return classes\n",
    "    return None\n",
    "\n",
    "def getPredicates(text, topK = 20):\n",
    "    \"\"\"\n",
    "    text: string about predicate\n",
    "    returning a dictionary of predicates ordered by similarities\n",
    "    \"\"\"\n",
    "    textEmbedding = sbert.encode(text, convert_to_tensor=True)\n",
    "    # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "    cosScores = util.pytorch_cos_sim(textEmbedding, torch.stack(list(predicateEmbedding.values())))[0]\n",
    "    topResults = torch.topk(cosScores, k=topK)\n",
    "    predicates = {}\n",
    "    for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "        predicates[list(predicateEmbedding.keys())[idx]] = (rank, score.item())\n",
    "    return predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4211ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entitySearchClass(query, topK=20, minSim=0.5, indexType='class', pathType=None):\n",
    "    \"\"\"\n",
    "    In this approach:\n",
    "    1. Query is chunked into entities and classified into biomedical phrases and predicate\n",
    "    2. Connect predicate to biomedical phrase\n",
    "    3. If indexType is 'class', generate vector for biomedical phrase\n",
    "    4. If indexType is 'class_predicate', generate vector for biomedical phrase and predicate pair\n",
    "    5. Combine vectors becoming one vector using mean function\n",
    "    6. Get similar entities encoding class_predicate using cosine similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = nlp(query)\n",
    "    \n",
    "    ontoClasses = []\n",
    "    predicates = []\n",
    "    validClassPredicates = {}\n",
    "    offset2Class = {}\n",
    "    for ent in doc.ents:\n",
    "        predicateScores = getPredicates(ent.text, topK=1)\n",
    "        pScore = list(predicateScores.values())[0][1]\n",
    "        classScores = getClasses(ent.text, topK=1)\n",
    "        cScore = list(classScores.values())[0][1]\n",
    "        if cScore >= pScore:\n",
    "            ontoClasses += [ent]\n",
    "            for token in ent:\n",
    "                offset2Class[token.i] = ent\n",
    "        elif indexType=='class_predicate' and pScore >= minSim:\n",
    "            predicates += [ent]\n",
    "    \n",
    "    if len(ontoClasses)==0: \n",
    "        ontoClasses = [doc]\n",
    "    \n",
    "    \n",
    "    # check the entities describe by predicate (usually predicate's child)\n",
    "    for ent in predicates:\n",
    "        for token in ent:\n",
    "            for child in token.children:\n",
    "                if child.i in offset2Class:\n",
    "                    idx = ontoClasses.index(offset2Class[child.i])\n",
    "                    if idx not in validClassPredicates:\n",
    "                        validClassPredicates[idx] = [ent]\n",
    "                    else:\n",
    "                        validClassPredicates[idx] += [ent]\n",
    "                    break # only consider the closest class. remove break if considering all classes\n",
    "                \n",
    "    if indexType=='class':\n",
    "        classEmbeddings = [sbert.encode(ent.text, convert_to_tensor=True) for ent in ontoClasses]\n",
    "        textEmbedding = torch.mean(torch.stack(classEmbeddings, dim=0), dim=0)\n",
    "    elif indexType=='class_predicate':\n",
    "        classEmbeddings = []\n",
    "        for i in range(len(ontoClasses)):\n",
    "            classEmbedding = sbert.encode(ontoClasses[i].text, convert_to_tensor=True)\n",
    "            if i in validClassPredicates:\n",
    "                predicateEmbeddings = [sbert.encode(ent.text, convert_to_tensor=True) for ent in validClassPredicates[i]]\n",
    "                pathEmbedding = alpha * torch.mean(torch.stack(predicateEmbeddings, dim=0), dim=0)\n",
    "                classEmbedding = torch.mean(torch.stack([classEmbedding, pathEmbedding], dim=0), dim=0)\n",
    "            classEmbeddings += [classEmbedding]\n",
    "        textEmbedding = torch.mean(torch.stack(classEmbeddings, dim=0), dim=0)                                \n",
    "        \n",
    "    # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "    cosScores = util.pytorch_cos_sim(textEmbedding, entityEmbedding[indexType])[0]\n",
    "    topResults = torch.topk(cosScores, k=topK)\n",
    "    entities = {}\n",
    "    varIds = list(entityKeys.keys())\n",
    "    for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "        entities[varIds[idx]] = [rank, score.item(), entityKeys[varIds[idx]]]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa32583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entitySearchCombine(query, topK=20, minSim=0.5, indexType='class', pathType=None):\n",
    "    \"\"\"\n",
    "    In this approach: combining entitySearch and entitySearchClass\n",
    "    1. Query is chunked into entities and classified into biomedical phrases and predicate\n",
    "    2. Connect predicate to biomedical phrase\n",
    "    3. If indexType is 'class', generate vector for biomedical phrase\n",
    "    4. If indexType is 'class_predicate', generate vector for biomedical phrase and predicate pair\n",
    "    5. Combine vectors becoming one vector using mean function, named it as local vector\n",
    "    6. Get vector of query named it as global vector\n",
    "    7. Combine local vector and global vector\n",
    "    8. Get similar entities using cosine similarity\n",
    "    9. Return topK result in descending\n",
    "    \"\"\"\n",
    "\n",
    "    ### Get local query embedding \n",
    "    \n",
    "    doc = nlp(query)\n",
    "    \n",
    "    ontoClasses = []\n",
    "    predicates = []\n",
    "    validClassPredicates = {}\n",
    "    offset2Class = {}\n",
    "    cScores = []\n",
    "    for ent in doc.ents:\n",
    "        predicateScores = getPredicates(ent.text, topK=1)\n",
    "        pScore = list(predicateScores.values())[0][1]\n",
    "        classScores = getClasses(ent.text, topK=1)\n",
    "        cScore = list(classScores.values())[0][1]\n",
    "        if cScore >= pScore:\n",
    "            cScores += [cScore]\n",
    "            ontoClasses += [ent]\n",
    "            for token in ent:\n",
    "                offset2Class[token.i] = ent\n",
    "        elif indexType =='class_predicate' and pScore >= minSim:\n",
    "            predicates += [ent]\n",
    "    \n",
    "    if len(ontoClasses) == 0: \n",
    "        ontoClasses = [doc]\n",
    "        cScores = [list(getClasses(query, topK=1).values())[0][1]]\n",
    "            \n",
    "            \n",
    "    # check the entities describe by predicate (usually predicate's child)\n",
    "    for ent in predicates:\n",
    "        for token in ent:\n",
    "            for child in token.children:\n",
    "                if child.i in offset2Class:\n",
    "                    idx = ontoClasses.index(offset2Class[child.i])\n",
    "                    if idx not in validClassPredicates:\n",
    "                        validClassPredicates[idx] = [ent]\n",
    "                    else:\n",
    "                        validClassPredicates[idx] += [ent]\n",
    "                    break # only consider the closest class. remove break if considering all classes\n",
    "                \n",
    "    if indexType=='class':\n",
    "        classEmbeddings = [sbert.encode(ent.text, convert_to_tensor=True) for ent in ontoClasses]\n",
    "        textEmbedding = torch.mean(torch.stack(classEmbeddings, dim=0), dim=0)\n",
    "    elif indexType=='class_predicate':\n",
    "        classEmbeddings = []\n",
    "        for i in range(len(ontoClasses)):\n",
    "            classEmbedding = sbert.encode(ontoClasses[i].text, convert_to_tensor=True)\n",
    "            if i in validClassPredicates:\n",
    "                predicateEmbeddings = [sbert.encode(ent.text, convert_to_tensor=True) for ent in validClassPredicates[i]]\n",
    "                pathEmbedding = alpha * torch.mean(torch.stack(predicateEmbeddings, dim=0), dim=0)\n",
    "                classEmbedding = torch.mean(torch.stack([classEmbedding, pathEmbedding], dim=0), dim=0)\n",
    "            classEmbeddings += [classEmbedding]\n",
    "        textEmbedding = torch.mean(torch.stack(classEmbeddings, dim=0), dim=0)                                \n",
    "        \n",
    "    ### Get global query embedding\n",
    "    textEmbeddingGlobal = sbert.encode(query, convert_to_tensor=True)\n",
    "    ### Combine global and local embedding\n",
    "    factor = sum(cScores)/len(cScores)\n",
    "    textEmbedding = torch.mean(torch.stack([textEmbeddingGlobal, factor * textEmbedding], dim=0), dim=0)       \n",
    "    \n",
    "    # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "    cosScores = util.pytorch_cos_sim(textEmbedding, entityEmbedding[indexType])[0]\n",
    "    topResults = torch.topk(cosScores, k=topK)\n",
    "    entities = {}\n",
    "    varIds = list(entityKeys.keys())\n",
    "    for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "        entities[varIds[idx]] = [rank, score.item(), entityKeys[varIds[idx]]]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc11426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is experimenting with predicate use decided using classifier\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "modelClassifier = AutoModelForSequenceClassification.from_pretrained('casbert_resources/pmr_selection_model/', num_labels=2)\n",
    "\n",
    "def classifyQuery(model, sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.logits.argmax(dim=-1)[0]\n",
    "\n",
    "def entitySearchCombine2(query, topK=20, minSim=0.5, indexType=None, pathType=None):\n",
    "    \"\"\"\n",
    "    In this approach: combining entitySearch and entitySearchClass\n",
    "    1. Query is chunked into entities and classified into biomedical phrases and predicate\n",
    "    2. Connect predicate to biomedical phrase\n",
    "    3. Here, the query is classify into 'class' or 'class_predicate'\n",
    "        a. If indexType is 'class', generate vector for biomedical phrase\n",
    "        b. If indexType is 'class_predicate', generate vector for biomedical phrase and predicate pair\n",
    "    4. Combine vectors becoming one vector using mean function, named it as local vector\n",
    "    5. Get vector of query named it as global vector\n",
    "    6. Combine local vector and global vector\n",
    "    7. Get similar entities using cosine similarity\n",
    "    8. Return topK result in descending\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get local query embedding \n",
    "    \n",
    "    doc = nlp(query)\n",
    "    \n",
    "    ontoClasses = []\n",
    "    predicates = []\n",
    "    validClassPredicates = {}\n",
    "    offset2Class = {}\n",
    "    for ent in doc.ents:\n",
    "       \n",
    "        predicateScores = getPredicates(ent.text, topK=1)\n",
    "        pScore = list(predicateScores.values())[0][1]\n",
    "        classScores = getClasses(ent.text, topK=1)\n",
    "        cScore = list(classScores.values())[0][1]\n",
    "        if cScore >= pScore:\n",
    "            ontoClasses += [ent]\n",
    "            for token in ent:\n",
    "                offset2Class[token.i] = ent\n",
    "        else:\n",
    "            predicates += [ent]\n",
    "    \n",
    "    if len(ontoClasses) == 0: \n",
    "        ontoClasses = [doc]\n",
    "            \n",
    "    # check the entities describe by predicate (usually predicate's child)\n",
    "    for ent in predicates:\n",
    "        for token in ent:\n",
    "            for child in token.children:\n",
    "                if child.i in offset2Class:\n",
    "                    idx = ontoClasses.index(offset2Class[child.i])\n",
    "                    if idx not in validClassPredicates:\n",
    "                        validClassPredicates[idx] = [ent]\n",
    "                    else:\n",
    "                        validClassPredicates[idx] += [ent]\n",
    "                    break # only consider the closest class. remove break if considering all classes\n",
    "    \n",
    "    classEmbeddings = []\n",
    "    for i in range(len(ontoClasses)):\n",
    "        classEmbedding = sbert.encode(ontoClasses[i].text, convert_to_tensor=True)\n",
    "        if i in validClassPredicates:\n",
    "            predicateEmbeddings = [sbert.encode(ent.text, convert_to_tensor=True) for ent in validClassPredicates[i]]\n",
    "            pathEmbedding = torch.mean(torch.stack(predicateEmbeddings, dim=0), dim=0)\n",
    "            classEmbedding = torch.mean(torch.stack([classEmbedding, pathEmbedding], dim=0), dim=0)\n",
    "        classEmbeddings += [classEmbedding]\n",
    "    textEmbedding = torch.mean(torch.stack(classEmbeddings, dim=0), dim=0)      \n",
    "        \n",
    "    ### Get global query embedding\n",
    "    textEmbeddingGlobal = sbert.encode(query, convert_to_tensor=True)\n",
    "    ### Combine global and local embedding\n",
    "    textEmbedding = torch.mean(torch.stack([textEmbeddingGlobal, textEmbedding], dim=0), dim=0)       \n",
    "    \n",
    "    # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "    bestType = classifyQuery(modelClassifier, query)\n",
    "    if bestType == 0:\n",
    "        cosScores = util.pytorch_cos_sim(textEmbedding, entityEmbedding['class'])[0]\n",
    "    else:\n",
    "        cosScores = util.pytorch_cos_sim(textEmbedding, entityEmbedding['class_predicate'])[0]\n",
    "    \n",
    "    topResults = torch.topk(cosScores, k=topK)\n",
    "    entities = {}\n",
    "    varIds = list(entityKeys.keys())\n",
    "    for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "        entities[varIds[idx]] = [rank, score.item(), entityKeys[varIds[idx]]]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c3b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entitySearchDetail(query, topK=20, minSim=0.5, indexType='class', pathType='multi'):\n",
    "    \"\"\"\n",
    "    In this approach:\n",
    "    1. Query is chunked into pairs of biomedical phrases - predicate\n",
    "    2. Get vector for each pair\n",
    "    3. Get the most similar ontology class - predicate pair for all biomedical phrases - predicate pair using cosine similarity\n",
    "    4. Get all entities having ontology class - predicate pair and sum the similarity\n",
    "    5. Return with descendant order\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    This approach is diferent. It index ontology class - path embedding to varId. Rank is based on the total match.\n",
    "    Utilise scispacy to chunk query to key words\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = nlp(query)\n",
    "    \n",
    "    candidatePredicateClass = {}\n",
    "    predicateClassTexts = list(classPredicateMap[pathType].keys())\n",
    "    \n",
    "    # check predicates and combine it to previous and next ontology class\n",
    "    offset2Token = {t.i:t.text for t in doc}\n",
    "    entOffsets = []\n",
    "    for ent in doc.ents:\n",
    "        predicateScores = getPredicates(ent.text, topK=1)\n",
    "        pScore = list(predicateScores.values())[0][1]\n",
    "        entityScores = getClasses(ent.text, topK=1)\n",
    "        eScore = list(entityScores.values())[0][1]\n",
    "        if eScore >= pScore:\n",
    "            entOffsets += [range(ent.start, ent.end)]\n",
    "        else:\n",
    "            for token in ent:\n",
    "                ancestorOffsets = [t.i for t in token.ancestors]\n",
    "                for ancestorOffset in ancestorOffsets:\n",
    "                    offset2Token[ancestorOffset] = offset2Token[ancestorOffset] + ' ' + token.text\n",
    "                    \n",
    "    finalPhrases = [' '.join([offset2Token[i] for i in offset]) for offset in entOffsets]\n",
    "    \n",
    "    if len(finalPhrases)==0: finalPhrases = [text]\n",
    "    \n",
    "    for keyword in finalPhrases:\n",
    "        textEmbedding = sbert.encode(keyword, convert_to_tensor=True)\n",
    "        # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "        cosScores = util.pytorch_cos_sim(textEmbedding, classPredicateEmbedding[pathType])[0]\n",
    "        topResults = torch.topk(cosScores, k=topK)\n",
    "        for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "            if predicateClassTexts[idx] not in candidatePredicateClass:\n",
    "                candidatePredicateClass[predicateClassTexts[idx]] = score.item()\n",
    "            elif candidatePredicateClass[predicateClassTexts[idx]] < score:\n",
    "                candidatePredicateClass[predicateClassTexts[idx]] = score.item()\n",
    "    \n",
    "    results = {}\n",
    "    for candidate, score in candidatePredicateClass.items():\n",
    "        varIds = classPredicateMap[pathType][candidate]\n",
    "        for varId in varIds:\n",
    "            if varId not in results:\n",
    "                results[varId] = score\n",
    "            else:\n",
    "                results[varId] += score\n",
    "    topResults = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    entities = {}\n",
    "    for rank, (varId, score) in enumerate(dict(topResults[:topK]).items()):\n",
    "        entities[varId] = [rank, score, entityKeys[varId]]\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entitySearchWithRefinement(query, topK=20, indexType='class', pathType='single', minSim=0):\n",
    "    \"\"\"\n",
    "    In this approach:\n",
    "    1. get topK entities using entitySearh method\n",
    "    2. refine the result by:\n",
    "        a. convert query to vector\n",
    "        b. get ontology class - predicate pairs based on query vector (take len(query) pairs)\n",
    "        c. for each entity having pairs and appear in 1 add the similarity score\n",
    "        d. sorter the new result.\n",
    "    \"\"\"\n",
    "    # global similarity\n",
    "    globalResults = entitySearch(query, topK=topK, indexType=indexType)\n",
    "    \n",
    "    # local similarity (ontology class level)\n",
    "    entEmbedding = sbert.encode(query, convert_to_tensor=True)\n",
    "    cosScores = util.pytorch_cos_sim(entEmbedding, classPredicateEmbedding[pathType])[0]\n",
    "    localResults = torch.topk(cosScores, k=len(query.split()))\n",
    "    predicateClassTexts = list(classPredicateMap[pathType].keys())\n",
    "    for score, idx in zip(localResults[0], localResults[1]):\n",
    "        dataId = predicateClassTexts[idx]\n",
    "        for elementId in classPredicateMap[pathType][dataId]:\n",
    "            if elementId in globalResults:\n",
    "                globalResults[elementId][1]+=score\n",
    "                \n",
    "    sortedResults = dict(sorted(globalResults.items(), key=lambda e: e[1][1], reverse=True))\n",
    "    for rank, elementId in enumerate(sortedResults.keys()):\n",
    "        sortedResults[elementId][0] = rank\n",
    "            \n",
    "    return sortedResults\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a07d31",
   "metadata": {},
   "source": [
    "### Now check for TF-IDF BM-25, for based comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def camel_case_split(identifier):\n",
    "    matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
    "    return [m.group(0) for m in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a307d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### organised variable text as a plain text then store it into dataframe\n",
    "\n",
    "# loop for each variable\n",
    "varTexts = {'varId':[], 'name':[], 'name_synonym':[], 'name_synonym_def':[], 'name_synonym_predicate':[]}\n",
    "for varId, value in variables['data'].items():\n",
    "    \n",
    "    names = []\n",
    "    synonyms = []\n",
    "    definitions = []\n",
    "    predicates = []\n",
    "    if 'rdfLeaves' in value:\n",
    "        for leaf in value['rdfLeaves']:\n",
    "            leaf = str(leaf).strip()\n",
    "            # get ontology class para\n",
    "            if leaf.startswith('http'):\n",
    "                classId = leaf.rsplit('/',1)[-1].rsplit('#',1)[-1].replace('_',':')\n",
    "            elif leaf.startswith('urn:miriam'):\n",
    "                classId = leaf.rsplit(':',1)[-1].replace('%3A',':')\n",
    "            if leaf.startswith('http') or leaf.startswith('urn:miriam'):\n",
    "                textFeature = getClassText(classId, features=['name', 'synonym', 'def'])\n",
    "                if len(textFeature)==0: continue\n",
    "                names += [textFeature['name']]\n",
    "                synonyms += ['' if not isinstance(textFeature['synonym'], str) else textFeature['synonym']]\n",
    "                definitions += ['' if not isinstance(textFeature['def'], str) else textFeature['def']]\n",
    "                predicates += [' '.join([' '.join(camel_case_split(p)).lower() for ps in entityKeys[varId]['classes'][classId]['path'] for p in ps])]\n",
    "    if len(names)==0: continue\n",
    "    varTexts['varId'] += [varId]\n",
    "    varTexts['name'] += [', '.join(set(names))]\n",
    "    varTexts['name_synonym'] += [', '.join(set(names + synonyms))]\n",
    "    varTexts['name_synonym_def'] += [', '.join(set(names + synonyms + definitions))]\n",
    "    varTexts['name_synonym_predicate'] += [', '.join(set(names + synonyms + predicates))]\n",
    "\n",
    "dfVarTexts = pd.DataFrame(varTexts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Implementation of OKapi BM25 with sklearn's TfidfVectorizer\n",
    "Distributed as CC-0 (https://creativecommons.org/publicdomain/zero/1.0/)\n",
    "\"\"\"\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "class BM25(object):\n",
    "    def __init__(self, b=0.75, k1=1.6):\n",
    "        self.vectorizer = TfidfVectorizer(norm=None, smooth_idf=False)\n",
    "        self.b = b\n",
    "        self.k1 = k1\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\" Fit IDF to documents X \"\"\"\n",
    "        self.vectorizer.fit(X)\n",
    "        y = super(TfidfVectorizer, self.vectorizer).transform(X)\n",
    "        self.avdl = y.sum(1).mean()\n",
    "\n",
    "    def transform(self, q, X):\n",
    "        \"\"\" Calculate BM25 between query q and documents X \"\"\"\n",
    "        b, k1, avdl = self.b, self.k1, self.avdl\n",
    "\n",
    "        # apply CountVectorizer\n",
    "        X = super(TfidfVectorizer, self.vectorizer).transform(X)\n",
    "        len_X = X.sum(1).A1\n",
    "        q, = super(TfidfVectorizer, self.vectorizer).transform([q])\n",
    "        assert sparse.isspmatrix_csr(q)\n",
    "\n",
    "        # convert to csc for better column slicing\n",
    "        X = X.tocsc()[:, q.indices]\n",
    "        denom = X + (k1 * (1 - b + b * len_X / avdl))[:, None]\n",
    "        # idf(t) = log [ n / df(t) ] + 1 in sklearn, so it need to be coneverted\n",
    "        # to idf(t) = log [ n / df(t) ] with minus 1\n",
    "        idf = self.vectorizer._tfidf.idf_[None, q.indices] - 1.\n",
    "        numer = X.multiply(np.broadcast_to(idf, X.shape)) * (k1 + 1)                                                          \n",
    "        return (numer / denom).sum(1).A1\n",
    "\n",
    "\n",
    "\n",
    "#------------ End of library impl. Followings are the example -----------------\n",
    "bm25 = {}\n",
    "for col in dfVarTexts.columns[1:]:\n",
    "    bm25[col] = BM25()\n",
    "    bm25[col].fit(dfVarTexts[col])\n",
    "    \n",
    "\n",
    "def entitySearchBM25(query, topK=20, indexType='name_synonym', pathType='single', minSim=0):\n",
    "    \"\"\"\n",
    "    In this approach:\n",
    "    Simply using bag of word method BM25\n",
    "    \"\"\"\n",
    "    results = bm25[indexType].transform(query, dfVarTexts[indexType])\n",
    "\n",
    "    sortedResults = {}\n",
    "    for i in results.argsort()[-topK:][::-1]:\n",
    "        sortedResults[dfVarTexts.iloc[i,0]] = (results[i], dfVarTexts.iloc[i,1])\n",
    "        \n",
    "    return sortedResults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68abdf9",
   "metadata": {},
   "source": [
    "## Now run to measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf831b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'noPredicate':{}, 'withPredicate':{}, 'combine':{}}\n",
    "topK = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetType = 'noPredicate'\n",
    "querySet = queryTest[dataSetType]['2']\n",
    "results[dataSetType]['macro'] = getMAP(querySet, entitySearch, topK=topK, indexType='class')\n",
    "results[dataSetType]['macroWP'] = getMAP(querySet, entitySearch, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['micro'] = getMAP(querySet, entitySearchClass, topK=topK, indexType='class')\n",
    "results[dataSetType]['microWP'] = getMAP(querySet, entitySearchClass, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['mixed'] = getMAP(querySet, entitySearchCombine, topK=topK, indexType='class')\n",
    "results[dataSetType]['mixedWP'] = getMAP(querySet, entitySearchCombine, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['mixedCl'] = getMAP(querySet, entitySearchCombine2, topK=topK)\n",
    "results[dataSetType]['BM25'] = getMAP(querySet, entitySearchBM25, topK=topK, indexType='name_synonym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1567e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetType = 'withPredicate'\n",
    "querySet = queryTest[dataSetType]['2']\n",
    "results[dataSetType]['macro'] = getMAP(querySet, entitySearch, topK=topK, indexType='class')\n",
    "results[dataSetType]['macroWP'] = getMAP(querySet, entitySearch, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['micro'] = getMAP(querySet, entitySearchClass, topK=topK, indexType='class')\n",
    "results[dataSetType]['microWP'] = getMAP(querySet, entitySearchClass, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['mixed'] = getMAP(querySet, entitySearchCombine, topK=topK, indexType='class')\n",
    "results[dataSetType]['mixedWP'] = getMAP(querySet, entitySearchCombine, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['mixedCl'] = getMAP(querySet, entitySearchCombine2, topK=topK)\n",
    "results[dataSetType]['BM25'] = getMAP(querySet, entitySearchBM25, topK=topK, indexType='name_synonym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc81b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetType = 'combine'\n",
    "querySet = queryTest[dataSetType]\n",
    "results[dataSetType]['macro'] = getMAP(querySet, entitySearch, topK=topK, indexType='class')\n",
    "results[dataSetType]['macroWP'] = getMAP(querySet, entitySearch, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['micro'] = getMAP(querySet, entitySearchClass, topK=topK, indexType='class')\n",
    "results[dataSetType]['microWP'] = getMAP(querySet, entitySearchClass, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['mixed'] = getMAP(querySet, entitySearchCombine, topK=topK, indexType='class')\n",
    "results[dataSetType]['mixedWP'] = getMAP(querySet, entitySearchCombine, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['mixedCl'] = getMAP(querySet, entitySearchCombine2, topK=topK)\n",
    "results[dataSetType]['BM25'] = getMAP(querySet, entitySearchBM25, topK=topK, indexType='name_synonym')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2c294",
   "metadata": {},
   "source": [
    "### Analysis result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e91287",
   "metadata": {},
   "outputs": [],
   "source": [
    "globalResults = {'approach':[], 'noPredicate_MAP':[], 'noPredicate_MRR':[], 'withPredicate_MAP':[], 'withPredicate_MRR':[], 'combine_MAP':[], 'combine_MRR':[]}\n",
    "\n",
    "for approach in list(results.values())[0].keys():\n",
    "    globalResults['approach'] += [approach]\n",
    "    for dataType, v in results.items():\n",
    "        globalResults[dataType+'_MAP'] += [v[approach]['MAP']['score']]\n",
    "        globalResults[dataType+'_MRR'] += [v[approach]['MRR']['score']]\n",
    "\n",
    "df_globalResults = pd.DataFrame(globalResults)\n",
    "df_globalResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b92d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateQueryEntityScore(qTest):\n",
    "    for query,v in tqdm(qTest.items()):\n",
    "        pos = entityKeys[v['vars'][0]]['pos']\n",
    "        queryEmb = sbert.encode(query, convert_to_tensor=True)\n",
    "        entityEmb = entityEmbedding['class'][pos]\n",
    "        cosScore = util.pytorch_cos_sim(entityEmb, queryEmb)\n",
    "        v['score']  = cosScore.item()\n",
    "        \n",
    "updateQueryEntityScore(queryTest['noPredicate']['0'])\n",
    "updateQueryEntityScore(queryTest['noPredicate']['1'])\n",
    "updateQueryEntityScore(queryTest['noPredicate']['2'])\n",
    "updateQueryEntityScore(queryTest['withPredicate']['0'])\n",
    "updateQueryEntityScore(queryTest['withPredicate']['1'])\n",
    "updateQueryEntityScore(queryTest['withPredicate']['2'])\n",
    "updateQueryEntityScore(queryTest['combine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailResults = {'approach':[], 'dataType':[], 'query_Class_Sim':[], 'MAP':[], 'MRR':[]}\n",
    "queryReference = {'noPredicate':[v['score'] for k,v in queryTest['noPredicate']['2'].items()], \n",
    "                  'withPredicate':[v['score'] for k,v in queryTest['withPredicate']['2'].items()], \n",
    "                  'combine':[v['score'] for k,v in queryTest['combine'].items()]} \n",
    "\n",
    "for approach in list(results.values())[0].keys():\n",
    "    for dataType, v in results.items():\n",
    "        for a,b,c in zip(queryReference[dataType], list(v[approach]['MAP']['stat'].values()), list(v[approach]['MRR']['stat'].values())):\n",
    "            detailResults['approach'] += [approach]\n",
    "            detailResults['dataType'] += [dataType]\n",
    "            detailResults['query_Class_Sim'] += [a]\n",
    "            detailResults['MAP'] += [b]\n",
    "            detailResults['MRR'] += [c]\n",
    "\n",
    "        \n",
    "#         detailResults[dataType+'_MAP'] += [v[approach]['MAP']['score']]\n",
    "#         detailResults[dataType+'_MRR'] += [v[approach]['MRR']['score']]\n",
    "\n",
    "df_detailResults = pd.DataFrame(detailResults)\n",
    "df_detailResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e0579f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfPlot = df_detailResults[df_detailResults['dataType']=='combine']\n",
    "dfPlot.query_Class_Sim = np.floor(dfPlot.query_Class_Sim*10)/10\n",
    "dfPlot.loc[(dfPlot.query_Class_Sim == 1.0),'query_Class_Sim']=0.9\n",
    "\n",
    "dfPlot.query_Class_Sim = dfPlot.query_Class_Sim.astype(str)+'-'+(dfPlot.query_Class_Sim+0.1).round(1).astype(str)\n",
    "# dfPlot = dfPlot.groupby(['approach', 'query_Class_Sim'], as_index=False)['MAP', 'MRR'].mean()\n",
    "dfPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ax = sns.lineplot(x = \"query_Class_Sim\", y = \"MAP\", hue=\"approach\", data = dfPlot)\n",
    "order = dfPlot['query_Class_Sim'].unique().tolist()\n",
    "order.sort()\n",
    "ax = sns.factorplot(x = \"query_Class_Sim\", y = \"MAP\", hue=\"approach\", data = dfPlot, order=order, legend=False)\n",
    "ax.despine(left=True)\n",
    "plt.legend(loc='right')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches( 10, 8)\n",
    "ax.set(xlabel=\"'Query - Entity's Terms' Similarity\", ylabel=\"mAP@10\")\n",
    "\n",
    "counts = tuple((100.*dfPlot.groupby('query_Class_Sim').count()['approach']/dfPlot.shape[0]).round(1).astype(str)+'%')\n",
    "print(counts)\n",
    "for i, c in enumerate(counts):\n",
    "    pos= (i*0.91, 0.2+i*0.1) if c not in counts[-3:] else (i*0.95, 1)\n",
    "    plt.annotate(c, xy = pos, \n",
    "             fontsize = 8, xytext = pos, \n",
    "             color = 'g')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70486a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('casbert_results/pmr_results.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac65c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
