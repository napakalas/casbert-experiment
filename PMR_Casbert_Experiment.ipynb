{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f9d29c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Experiment: Composite Annotation Search Using BERT for the PMR\n",
    "- BERT is used to convert compositely annotated entities in biosimulation model repository (PMR) as vectors/embeddings.\n",
    "- A query is converted into vector/embedding using BERT\n",
    "- Calculate the similarity of the query's vector to entity's vectors\n",
    "  - using cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce35b6",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df3cc35-dac3-4f13-a82a-542e69fcb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sentence_transformers import util\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0396b068-4ae4-444d-aa5a-1c849db80fb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2933cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of entity embeddings\n",
    "entityEmbedding = torch.load('casbert_resources/pmr_entities.pt')\n",
    "\n",
    "with open('casbert_resources/pmr_entities.json', 'r') as fp:\n",
    "    entityKeys = json.load(fp)\n",
    "\n",
    "# Dict of predicate embeddings\n",
    "predicateEmbedding = torch.load('casbert_resources/pmr_predicates.pt')\n",
    "\n",
    "# Dict of ontology class embedding\n",
    "ontoEmbedding = torch.load('casbert_resources/pmr_classes.pt')\n",
    "\n",
    "# load ontology dictionaries\n",
    "import gzip, pickle\n",
    "file = gzip.GzipFile('casbert_resources/ontoDf.gz', 'rb')\n",
    "ontologies = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "with open('casbert_resources/pmr_list_of_variable.json', 'r') as fp:\n",
    "    variables = json.load(fp)\n",
    "    \n",
    "# Query Set for test data\n",
    "with open('casbert_resources/pmr_query_test.json', 'r') as fp:\n",
    "    queryTest = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a31d22d-c47f-4ecc-82d9-9409154dad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of ontology class embedding\n",
    "ontoEmbedding = torch.load('casbert_resources/pmr_classes.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6221cd05-95cb-4f13-8bee-7e5012930396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': tensor([[-1.8919e-01, -4.6816e-01,  7.5755e-01,  ...,  1.4521e-01,\n",
       "          -3.2926e-01, -3.4300e-01],\n",
       "         [-1.9775e-01, -1.1170e+00,  5.9477e-01,  ...,  6.6005e-01,\n",
       "           5.7164e-02, -1.1519e+00],\n",
       "         [-6.2371e-01, -5.3244e-01, -7.4364e-02,  ...,  3.0324e-01,\n",
       "           3.7459e-01, -1.6725e+00],\n",
       "         ...,\n",
       "         [-1.0741e-03, -5.8975e-02, -2.4341e-02,  ...,  4.7991e-01,\n",
       "           1.7974e-01, -3.0277e-01],\n",
       "         [ 1.0023e-01,  9.3666e-02,  5.9138e-02,  ...,  9.6398e-01,\n",
       "           3.2167e-01, -2.3175e-01],\n",
       "         [ 1.0975e-01, -1.0907e-02, -4.3293e-01,  ...,  2.1721e-01,\n",
       "          -3.4227e-02, -1.2363e-01]]),\n",
       " 'synonym': tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0132, -0.1447, -0.0373,  ...,  0.4971,  0.1865, -0.2812],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2452, -0.0978, -0.6645,  ...,  0.2144,  0.1621, -0.0733]]),\n",
       " 'name_synonym': tensor([[-0.0946, -0.2341,  0.3788,  ...,  0.0726, -0.1646, -0.1715],\n",
       "         [-0.0989, -0.5585,  0.2974,  ...,  0.3300,  0.0286, -0.5759],\n",
       "         [-0.3119, -0.2662, -0.0372,  ...,  0.1516,  0.1873, -0.8362],\n",
       "         ...,\n",
       "         [ 0.0061, -0.1018, -0.0308,  ...,  0.4885,  0.1831, -0.2920],\n",
       "         [ 0.0501,  0.0468,  0.0296,  ...,  0.4820,  0.1608, -0.1159],\n",
       "         [ 0.1775, -0.0543, -0.5487,  ...,  0.2158,  0.0639, -0.0985]]),\n",
       " 'def': tensor([[-0.1984, -0.0226,  0.0993,  ...,  0.4390,  0.3985,  0.2261],\n",
       "         [-0.1832, -0.1485,  0.0606,  ...,  0.4250,  0.5116, -0.1912],\n",
       "         [-0.2878, -0.0921, -0.3573,  ...,  0.5259,  0.1660, -0.6263],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.1518, -0.1988, -0.3375,  ...,  0.1707,  0.2356, -0.0671]]),\n",
       " 'name_synonym_def': tensor([[-0.1292, -0.1636,  0.2856,  ...,  0.1947,  0.0231, -0.0390],\n",
       "         [-0.1270, -0.4218,  0.2184,  ...,  0.3617,  0.1896, -0.4477],\n",
       "         [-0.3038, -0.2082, -0.1439,  ...,  0.2764,  0.1802, -0.7662],\n",
       "         ...,\n",
       "         [ 0.0040, -0.0679, -0.0205,  ...,  0.3257,  0.1221, -0.1946],\n",
       "         [ 0.0334,  0.0312,  0.0197,  ...,  0.3213,  0.1072, -0.0772],\n",
       "         [ 0.0677, -0.1025, -0.4783,  ...,  0.2008,  0.1212, -0.0880]]),\n",
       " 'ClassId': ['GO:0022840',\n",
       "  'GO:0005262',\n",
       "  'GO:0034704',\n",
       "  'GO:0005516',\n",
       "  'FMA:62343',\n",
       "  'FMA:67225',\n",
       "  'CHEBI:39124',\n",
       "  'FMA:62338',\n",
       "  'GO:0030181',\n",
       "  'GO:0015085',\n",
       "  'GO:0006816',\n",
       "  'GO:0070588',\n",
       "  'GO:0051208',\n",
       "  'GO:0051563',\n",
       "  'GO:0030172',\n",
       "  'FMA:67901',\n",
       "  'FMA:62492',\n",
       "  'GO:0005245',\n",
       "  'GO:0005891',\n",
       "  'CHEBI:22984',\n",
       "  'GO:0005509',\n",
       "  'CHEBI:15422',\n",
       "  'CHEBI:5107',\n",
       "  'GO:0001518',\n",
       "  'GO:0005272',\n",
       "  'GO:0034706',\n",
       "  'GO:0005248',\n",
       "  'GO:0034705',\n",
       "  'GO:0005267',\n",
       "  'GO:0005251',\n",
       "  'CHEBI:26708',\n",
       "  'CHEBI:26216',\n",
       "  'GO:0070296',\n",
       "  'GO:0005391',\n",
       "  'GO:0006815',\n",
       "  'GO:0005890',\n",
       "  'FMA:74793',\n",
       "  'OPB:00340',\n",
       "  'FMA:66836',\n",
       "  'CHEBI:29108',\n",
       "  'FMA:63842',\n",
       "  'PR:P29994',\n",
       "  'OPB:00593',\n",
       "  'FMA:80352',\n",
       "  'PR:P20020',\n",
       "  'CHEBI:131186',\n",
       "  'FMA:54537',\n",
       "  'CHEBI:16761',\n",
       "  'FMA:54527',\n",
       "  'CHEBI:16526',\n",
       "  'OPB:01023',\n",
       "  'CHEBI:88003',\n",
       "  'CHEBI:14314',\n",
       "  'CHEBI:17138',\n",
       "  'CHEBI:17234',\n",
       "  'FMA:70022',\n",
       "  'CHEBI:28087',\n",
       "  'CHEBI:24996',\n",
       "  'CHEBI:16908',\n",
       "  'CHEBI:29101',\n",
       "  'CHEBI:33263',\n",
       "  'CHEBI:17287',\n",
       "  'CHEBI:18021',\n",
       "  'CHEBI:15361',\n",
       "  'OPB:00592',\n",
       "  'OPB:01658',\n",
       "  'FMA:62033',\n",
       "  'CHEBI:16796',\n",
       "  'FMA:62970',\n",
       "  'OPB:00045',\n",
       "  'GO:0004683',\n",
       "  'FMA:62390',\n",
       "  'GO:0005241',\n",
       "  'GO:0005242',\n",
       "  'GO:0022841',\n",
       "  'FMA:62387',\n",
       "  'GO:0042383',\n",
       "  'FMA:67964',\n",
       "  'GO:0016529',\n",
       "  'GO:0033017',\n",
       "  'FMA:67196',\n",
       "  'FMA:62353',\n",
       "  'GO:0005861',\n",
       "  'GO:0005250',\n",
       "  'GO:0005249',\n",
       "  'GO:0008076',\n",
       "  'CHEBI:38634',\n",
       "  'GO:0005219',\n",
       "  'FMA:226054',\n",
       "  'PR:000004305',\n",
       "  'FMA:67883',\n",
       "  'FMA:62236',\n",
       "  'PR:Q15413',\n",
       "  'FMA:67122',\n",
       "  'CHEBI:17996',\n",
       "  'OPB:01581',\n",
       "  'CHEBI:29103',\n",
       "  'OPB:00378',\n",
       "  'FMA:84786',\n",
       "  'OPB:00318',\n",
       "  'GO:0004890',\n",
       "  'GO:0015269',\n",
       "  'FMA:30322',\n",
       "  'GO:1990512',\n",
       "  'CHEBI:80331',\n",
       "  'CHEBI:15351',\n",
       "  'GO:0015742',\n",
       "  'GO:0015139',\n",
       "  'GO:0006840',\n",
       "  'CHEBI:35391',\n",
       "  'CHEBI:29995',\n",
       "  'GO:0051503',\n",
       "  'GO:0000295',\n",
       "  'CHEBI:30769',\n",
       "  'CHEBI:15346',\n",
       "  'CHEBI:16238',\n",
       "  'CHEBI:17877',\n",
       "  'GO:0004333',\n",
       "  'CHEBI:14321',\n",
       "  'GO:0015259',\n",
       "  'CHEBI:29987',\n",
       "  'CHEBI:36454',\n",
       "  'CHEBI:16087',\n",
       "  'CHEBI:36453',\n",
       "  'CHEBI:50220',\n",
       "  'CHEBI:25107',\n",
       "  'CHEBI:13389',\n",
       "  'GO:0008483',\n",
       "  'GO:0000276',\n",
       "  'GO:0000275',\n",
       "  'CHEBI:15380',\n",
       "  'CHEBI:51381',\n",
       "  'GO:0019465',\n",
       "  'GO:0047319',\n",
       "  'GO:0046571',\n",
       "  'GO:0003878',\n",
       "  'CHEBI:29806',\n",
       "  'CHEBI:50921',\n",
       "  'CHEBI:37154',\n",
       "  'GO:0004448',\n",
       "  'GO:0004449',\n",
       "  'GO:0045242',\n",
       "  'GO:0005962',\n",
       "  'GO:0004450',\n",
       "  'GO:0006102',\n",
       "  'GO:0005947',\n",
       "  'GO:0016615',\n",
       "  'GO:0046554',\n",
       "  'CHEBI:15595',\n",
       "  'GO:0045281',\n",
       "  'GO:0000104',\n",
       "  'CHEBI:30031',\n",
       "  'CHEBI:30779',\n",
       "  'GO:0004056',\n",
       "  'PR:P16615',\n",
       "  'FMA:14067',\n",
       "  'OPB:01097',\n",
       "  'CHEBI:30742',\n",
       "  'GO:0005862',\n",
       "  'FMA:67896',\n",
       "  'GO:0005388',\n",
       "  'GO:0035976',\n",
       "  'GO:1990513',\n",
       "  'GO:0005667',\n",
       "  'GO:0035189',\n",
       "  'FMA:67394',\n",
       "  'PR:O35054',\n",
       "  'CHEBI:15378',\n",
       "  'FMA:84666',\n",
       "  'PR:G3X939',\n",
       "  'CHEBI:28938',\n",
       "  'OPB:00299',\n",
       "  'FMA:17705',\n",
       "  'MA:0002598',\n",
       "  'MA:0002586',\n",
       "  'CL:1001286',\n",
       "  'OPB:01064',\n",
       "  'OPB:01001',\n",
       "  'PR:Q5I0H4',\n",
       "  'PR:Q9QY96',\n",
       "  'FMA:84669',\n",
       "  'FMA:9673',\n",
       "  'FMA:70982',\n",
       "  'CHEBI:17544',\n",
       "  'FMA:70973',\n",
       "  'OPB:00506',\n",
       "  'PR:P15387',\n",
       "  'PR:Q6Q760',\n",
       "  'PR:P06685',\n",
       "  'PR:P26432',\n",
       "  'PR:Q06393',\n",
       "  'PR:P55018',\n",
       "  'FMA:74550',\n",
       "  'PR:F1LZ52',\n",
       "  'FMA:9672',\n",
       "  'PR:O14234',\n",
       "  'PR:P26433',\n",
       "  'CHEBI:24838',\n",
       "  'OPB:00293',\n",
       "  'FMA:226050',\n",
       "  'GO:0005432',\n",
       "  'CHEBI:39000',\n",
       "  'CHEBI:21008',\n",
       "  'FMA:85704',\n",
       "  'GO:0005739',\n",
       "  'GO:0008443',\n",
       "  'CHEBI:17552',\n",
       "  'PR:000022358',\n",
       "  'CHEBI:42471',\n",
       "  'CHEBI:15996',\n",
       "  'CHEBI:48518',\n",
       "  'GO:1990454',\n",
       "  'GO:0014701',\n",
       "  'GO:1990629',\n",
       "  'GO:0000164',\n",
       "  'CHEBI:16356',\n",
       "  'CL:0000359',\n",
       "  'CHEBI:16480',\n",
       "  'PR:P37089',\n",
       "  'PR:Q9Z0S6',\n",
       "  'PR:000014527',\n",
       "  'GO:0005254',\n",
       "  'OPB:00425',\n",
       "  'OPB:00295',\n",
       "  'GO:0060402',\n",
       "  'GO:0051561',\n",
       "  'GO:0006851',\n",
       "  'GO:0051560',\n",
       "  'FMA:67257',\n",
       "  'FMA:63841',\n",
       "  'GO:0005829',\n",
       "  'CHEBI:15343',\n",
       "  'CHEBI:16027',\n",
       "  'CHEBI:16001',\n",
       "  'CHEBI:16236',\n",
       "  'CHEBI:16905',\n",
       "  'CHEBI:28602',\n",
       "  'CHEBI:15946',\n",
       "  'CHEBI:17665',\n",
       "  'CHEBI:17754',\n",
       "  'CHEBI:15846',\n",
       "  'CHEBI:17835',\n",
       "  'CHEBI:17794',\n",
       "  'CHEBI:29052',\n",
       "  'CHEBI:16108',\n",
       "  'GO:0015444',\n",
       "  'CHEBI:30741',\n",
       "  'CHEBI:30740',\n",
       "  'CHEBI:38215',\n",
       "  'GO:0016286',\n",
       "  'GO:0008282',\n",
       "  'GO:0006852',\n",
       "  'CHEBI:38808',\n",
       "  'CHEBI:50510',\n",
       "  'GO:0008332',\n",
       "  'GO:0008331',\n",
       "  'GO:0048763',\n",
       "  'GO:0070509',\n",
       "  'GO:0008511',\n",
       "  'GO:0015271',\n",
       "  'GO:0070978',\n",
       "  'GO:0019870',\n",
       "  'CHEBI:50509',\n",
       "  'PR:000015160',\n",
       "  'PR:000014925',\n",
       "  'OPB:01364',\n",
       "  'GO:0014871',\n",
       "  'GO:0014868',\n",
       "  'PR:P48768',\n",
       "  'PR:P50993',\n",
       "  'GO:0015272',\n",
       "  'GO:0051480',\n",
       "  'FMA:16016',\n",
       "  'GO:0005783',\n",
       "  'CHEBI:64338',\n",
       "  'GO:0016887',\n",
       "  'CHEBI:70817',\n",
       "  'CHEBI:15379',\n",
       "  'GO:0060401',\n",
       "  'MA:0001652',\n",
       "  'MA:0002596',\n",
       "  'GO:0060075',\n",
       "  'GO:0042391',\n",
       "  'GO:0030322',\n",
       "  'GO:0055075',\n",
       "  'SBO:0000252',\n",
       "  'SBO:0000027',\n",
       "  'SBO:0000025',\n",
       "  'SBO:0000186',\n",
       "  'GO:0005680',\n",
       "  'SBO:0000297',\n",
       "  'PR:000015207',\n",
       "  'GO:0009674',\n",
       "  'GO:0001965',\n",
       "  'GO:0015276',\n",
       "  'GO:0022834',\n",
       "  'GO:0005229',\n",
       "  'GO:0043855',\n",
       "  'GO:0005220',\n",
       "  'GO:0034703',\n",
       "  'GO:0005261',\n",
       "  'CL:0002593',\n",
       "  'GO:0034707',\n",
       "  'GO:0005247',\n",
       "  'FMA:67840',\n",
       "  'FMA:9906',\n",
       "  'FMA:72444',\n",
       "  'OPB:00089',\n",
       "  'OPB:00410',\n",
       "  'OPB:00154',\n",
       "  'FMA:67895',\n",
       "  'FMA:9462',\n",
       "  'PR:Q01728',\n",
       "  'PR:P11505',\n",
       "  'PR:P11507',\n",
       "  'PR:B0LPN4',\n",
       "  'GO:0070095',\n",
       "  'GO:0042132',\n",
       "  'GO:0043235',\n",
       "  'CL:0000197',\n",
       "  'OPB:01043',\n",
       "  'OPB:00446',\n",
       "  'FMA:67120',\n",
       "  'FMA:72448',\n",
       "  'CHEBI:30120',\n",
       "  'PR:000005057',\n",
       "  'CHEBI:18035',\n",
       "  'CHEBI:16235',\n",
       "  'OPB:00015',\n",
       "  'CHEBI:25450',\n",
       "  'OPB:01622',\n",
       "  'CHEBI:33569',\n",
       "  'OPB:01298',\n",
       "  'CHEBI:37328',\n",
       "  'FMA:67945',\n",
       "  'CL:0002064']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontoEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d0d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT model used\n",
    "BERTModel = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "sbert = SentenceTransformer(BERTModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e94ab8",
   "metadata": {},
   "source": [
    "### Performance measure using Mean average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8643a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def averagePrecision(prediction):\n",
    "    if 1 not in prediction:\n",
    "        return 0\n",
    "    tot = 0\n",
    "    for idx, p in enumerate(prediction):\n",
    "        if p>0:\n",
    "            tot += sum(prediction[0:idx+1])/(idx+1)\n",
    "    return tot/sum(prediction)\n",
    "\n",
    "def meanAP(predictions):\n",
    "    tap = 0\n",
    "    stat = {}\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "        ap = averagePrecision(prediction)\n",
    "        stat[idx] = ap\n",
    "        tap += ap\n",
    "    return {'score':tap/len(predictions), 'stat':stat}\n",
    "\n",
    "def meanRR(predictions):\n",
    "    trr = 0\n",
    "    stat = {}\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "        rr = 1/(prediction.index(1)+1) if 1 in prediction else 0\n",
    "        stat[idx] = rr\n",
    "        trr += rr\n",
    "    return {'score':trr/len(predictions), 'stat':stat}\n",
    "\n",
    "def getMAP(queries, searchFunction, indexType=None, pathType=None, topK=10, minSim=0.5):\n",
    "    predictions = []\n",
    "    for query, facts in tqdm(queries.items()):\n",
    "        results = searchFunction(query=query, topK=topK, indexType=indexType, pathType=pathType, minSim=minSim)\n",
    "        predictions += [[1 if varId in facts['vars'] else 0 for varId in results]]\n",
    "    MAP = meanAP(predictions)\n",
    "    return {'MAP':MAP,'MRR':meanRR(predictions)}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178afd5",
   "metadata": {},
   "source": [
    "### Searching functions\n",
    "Here we prepare several functions with different approah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In some functions, we utilise scispacy to locate phrases or concepts related to a query. \n",
    "# For example a query 'Calcium reverse membrane potential.' \n",
    "# is identified having 2 concepts of 'calcium' and 'reverse membrane potential'\n",
    "# For accurate identification we use 'en_core_sci_scibert' which required GPU for faster performance\n",
    "\n",
    "import en_core_sci_scibert\n",
    "nlp = en_core_sci_scibert.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entitySearch(query, topK=20, indexType='class', pathType=None, minSim=None):\n",
    "    \"\"\"\n",
    "    In this approach:\n",
    "    1. Get vector of query\n",
    "    2. Get similar entities using cosine similarity\n",
    "    3. Return topK result in descending\n",
    "    \"\"\"\n",
    "    textEmbedding = sbert.encode(query, convert_to_tensor=True)\n",
    "    # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "    cosScores = util.pytorch_cos_sim(textEmbedding, entityEmbedding[indexType])[0]\n",
    "    topResults = torch.topk(cosScores, k=topK)\n",
    "    entities = {}\n",
    "    varIds = list(entityKeys.keys())\n",
    "    for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "        entities[varIds[idx]] = [rank, score.item(), entityKeys[varIds[idx]]]\n",
    "    return entities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff3802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OntoEmbedding function\n",
    "\n",
    "classId_List = ontoEmbedding['ClassId']\n",
    "alpha = 0.22\n",
    "\n",
    "# returning text\n",
    "def getClassText(classId, features=['name']):\n",
    "    \"\"\"\n",
    "    features: name, synonym, parent, def\n",
    "    \"\"\"\n",
    "    corpus = {}\n",
    "    if classId in classId_List:\n",
    "        for feature in features:\n",
    "            corpus[feature] = ontologies.loc[classId][feature]\n",
    "    return corpus\n",
    "\n",
    "# returning ontology classes\n",
    "def getClasses(text, feature='name_synonym', topK = 20):\n",
    "    \"\"\"\n",
    "    feature: name, name_synonym, name_synonym_def, name_synonym_def, name_synonym_def_parent\n",
    "    \"\"\"\n",
    "    textEmbedding = sbert.encode(text, convert_to_tensor=True)\n",
    "    # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "    if feature in ontoEmbedding:\n",
    "        cosScores = util.pytorch_cos_sim(textEmbedding, ontoEmbedding[feature])[0]\n",
    "        topResults = torch.topk(cosScores, k=topK)\n",
    "        c = {}\n",
    "        for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "            classId = classId_List[idx.item()]\n",
    "            c[classId] = (rank, score.item(), ontologies.loc[classId]['name'])\n",
    "        return c\n",
    "    return None\n",
    "\n",
    "def getPredicates(text, topK = 20):\n",
    "    \"\"\"\n",
    "    text: string about predicate\n",
    "    returning a dictionary of predicates ordered by similarities\n",
    "    \"\"\"\n",
    "    textEmbedding = sbert.encode(text, convert_to_tensor=True)\n",
    "    # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "    cosScores = util.pytorch_cos_sim(textEmbedding, torch.stack(list(predicateEmbedding.values())))[0]\n",
    "    topResults = torch.topk(cosScores, k=topK)\n",
    "    predicates = {}\n",
    "    for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "        predicates[list(predicateEmbedding.keys())[idx]] = (rank, score.item())\n",
    "    return predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4211ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entitySearchClass(query, topK=20, minSim=0.5, indexType='class', pathType=None):\n",
    "    \"\"\"\n",
    "    In this approach:\n",
    "    1. Query is chunked into entities and classified into biomedical phrases and predicate\n",
    "    2. Connect predicate to biomedical phrase\n",
    "    3. If indexType is 'class', generate vector for biomedical phrase\n",
    "    4. If indexType is 'class_predicate', generate vector for biomedical phrase and predicate pair\n",
    "    5. Combine vectors becoming one vector using mean function\n",
    "    6. Get similar entities encoding class_predicate using cosine similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = nlp(query)\n",
    "    \n",
    "    ontoClasses = []\n",
    "    predicates = []\n",
    "    validClassPredicates = {}\n",
    "    offset2Class = {}\n",
    "    for ent in doc.ents:\n",
    "        predicateScores = getPredicates(ent.text, topK=1)\n",
    "        pScore = list(predicateScores.values())[0][1]\n",
    "        classScores = getClasses(ent.text, topK=1)\n",
    "        cScore = list(classScores.values())[0][1]\n",
    "        if cScore >= pScore:\n",
    "            ontoClasses += [ent]\n",
    "            for token in ent:\n",
    "                offset2Class[token.i] = ent\n",
    "        elif indexType=='class_predicate' and pScore >= minSim:\n",
    "            predicates += [ent]\n",
    "    \n",
    "    if len(ontoClasses)==0: \n",
    "        ontoClasses = [doc]\n",
    "    \n",
    "    \n",
    "    # check the entities describe by predicate (usually predicate's child)\n",
    "    for ent in predicates:\n",
    "        for token in ent:\n",
    "            for child in token.children:\n",
    "                if child.i in offset2Class:\n",
    "                    idx = ontoClasses.index(offset2Class[child.i])\n",
    "                    if idx not in validClassPredicates:\n",
    "                        validClassPredicates[idx] = [ent]\n",
    "                    else:\n",
    "                        validClassPredicates[idx] += [ent]\n",
    "                    break # only consider the closest class. remove break if considering all classes\n",
    "                \n",
    "    if indexType=='class':\n",
    "        classEmbeddings = [sbert.encode(ent.text, convert_to_tensor=True) for ent in ontoClasses]\n",
    "        textEmbedding = torch.mean(torch.stack(classEmbeddings, dim=0), dim=0)\n",
    "    elif indexType=='class_predicate':\n",
    "        classEmbeddings = []\n",
    "        for i in range(len(ontoClasses)):\n",
    "            classEmbedding = sbert.encode(ontoClasses[i].text, convert_to_tensor=True)\n",
    "            if i in validClassPredicates:\n",
    "                predicateEmbeddings = [sbert.encode(ent.text, convert_to_tensor=True) for ent in validClassPredicates[i]]\n",
    "                pathEmbedding = alpha * torch.mean(torch.stack(predicateEmbeddings, dim=0), dim=0)\n",
    "                classEmbedding = torch.mean(torch.stack([classEmbedding, pathEmbedding], dim=0), dim=0)\n",
    "            classEmbeddings += [classEmbedding]\n",
    "        textEmbedding = torch.mean(torch.stack(classEmbeddings, dim=0), dim=0)                                \n",
    "        \n",
    "    # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "    cosScores = util.pytorch_cos_sim(textEmbedding, entityEmbedding[indexType])[0]\n",
    "    topResults = torch.topk(cosScores, k=topK)\n",
    "    entities = {}\n",
    "    varIds = list(entityKeys.keys())\n",
    "    for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "        entities[varIds[idx]] = [rank, score.item(), entityKeys[varIds[idx]]]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa32583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entitySearchCombine(query, topK=20, minSim=0.5, indexType='class', pathType=None):\n",
    "    \"\"\"\n",
    "    In this approach: combining entitySearch and entitySearchClass\n",
    "    1. Query is chunked into entities and classified into biomedical phrases and predicate\n",
    "    2. Connect predicate to biomedical phrase\n",
    "    3. If indexType is 'class', generate vector for biomedical phrase\n",
    "    4. If indexType is 'class_predicate', generate vector for biomedical phrase and predicate pair\n",
    "    5. Combine vectors becoming one vector using mean function, named it as local vector\n",
    "    6. Get vector of query named it as global vector\n",
    "    7. Combine local vector and global vector\n",
    "    8. Get similar entities using cosine similarity\n",
    "    9. Return topK result in descending\n",
    "    \"\"\"\n",
    "\n",
    "    ### Get local query embedding \n",
    "    \n",
    "    doc = nlp(query)\n",
    "    \n",
    "    ontoClasses = []\n",
    "    predicates = []\n",
    "    validClassPredicates = {}\n",
    "    offset2Class = {}\n",
    "    cScores = []\n",
    "    for ent in doc.ents:\n",
    "        predicateScores = getPredicates(ent.text, topK=1)\n",
    "        pScore = list(predicateScores.values())[0][1]\n",
    "        classScores = getClasses(ent.text, topK=1)\n",
    "        cScore = list(classScores.values())[0][1]\n",
    "        if cScore >= pScore:\n",
    "            cScores += [cScore]\n",
    "            ontoClasses += [ent]\n",
    "            for token in ent:\n",
    "                offset2Class[token.i] = ent\n",
    "        elif indexType =='class_predicate' and pScore >= minSim:\n",
    "            predicates += [ent]\n",
    "    \n",
    "    if len(ontoClasses) == 0: \n",
    "        ontoClasses = [doc]\n",
    "        cScores = [list(getClasses(query, topK=1).values())[0][1]]\n",
    "            \n",
    "            \n",
    "    # check the entities describe by predicate (usually predicate's child)\n",
    "    for ent in predicates:\n",
    "        for token in ent:\n",
    "            for child in token.children:\n",
    "                if child.i in offset2Class:\n",
    "                    idx = ontoClasses.index(offset2Class[child.i])\n",
    "                    if idx not in validClassPredicates:\n",
    "                        validClassPredicates[idx] = [ent]\n",
    "                    else:\n",
    "                        validClassPredicates[idx] += [ent]\n",
    "                    break # only consider the closest class. remove break if considering all classes\n",
    "                \n",
    "    if indexType=='class':\n",
    "        classEmbeddings = [sbert.encode(ent.text, convert_to_tensor=True) for ent in ontoClasses]\n",
    "        textEmbedding = torch.mean(torch.stack(classEmbeddings, dim=0), dim=0)\n",
    "    elif indexType=='class_predicate':\n",
    "        classEmbeddings = []\n",
    "        for i in range(len(ontoClasses)):\n",
    "            classEmbedding = sbert.encode(ontoClasses[i].text, convert_to_tensor=True)\n",
    "            if i in validClassPredicates:\n",
    "                predicateEmbeddings = [sbert.encode(ent.text, convert_to_tensor=True) for ent in validClassPredicates[i]]\n",
    "                pathEmbedding = alpha * torch.mean(torch.stack(predicateEmbeddings, dim=0), dim=0)\n",
    "                classEmbedding = torch.mean(torch.stack([classEmbedding, pathEmbedding], dim=0), dim=0)\n",
    "            classEmbeddings += [classEmbedding]\n",
    "        textEmbedding = torch.mean(torch.stack(classEmbeddings, dim=0), dim=0)                                \n",
    "        \n",
    "    ### Get global query embedding\n",
    "    textEmbeddingGlobal = sbert.encode(query, convert_to_tensor=True)\n",
    "    ### Combine global and local embedding\n",
    "    factor = sum(cScores)/len(cScores)\n",
    "    textEmbedding = torch.mean(torch.stack([textEmbeddingGlobal, factor * textEmbedding], dim=0), dim=0)       \n",
    "    \n",
    "    # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "    cosScores = util.pytorch_cos_sim(textEmbedding, entityEmbedding[indexType])[0]\n",
    "    topResults = torch.topk(cosScores, k=topK)\n",
    "    entities = {}\n",
    "    varIds = list(entityKeys.keys())\n",
    "    for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "        entities[varIds[idx]] = [rank, score.item(), entityKeys[varIds[idx]]]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc11426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is experimenting with predicate use decided using classifier\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "modelClassifier = AutoModelForSequenceClassification.from_pretrained('casbert_resources/pmr_selection_model/', num_labels=2)\n",
    "\n",
    "def classifyQuery(model, sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.logits.argmax(dim=-1)[0]\n",
    "\n",
    "def entitySearchCombine2(query, topK=20, minSim=0.5, indexType=None, pathType=None):\n",
    "    \"\"\"\n",
    "    In this approach: combining entitySearch and entitySearchClass\n",
    "    1. Query is chunked into entities and classified into biomedical phrases and predicate\n",
    "    2. Connect predicate to biomedical phrase\n",
    "    3. Here, the query is classify into 'class' or 'class_predicate'\n",
    "        a. If indexType is 'class', generate vector for biomedical phrase\n",
    "        b. If indexType is 'class_predicate', generate vector for biomedical phrase and predicate pair\n",
    "    4. Combine vectors becoming one vector using mean function, named it as local vector\n",
    "    5. Get vector of query named it as global vector\n",
    "    6. Combine local vector and global vector\n",
    "    7. Get similar entities using cosine similarity\n",
    "    8. Return topK result in descending\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get local query embedding \n",
    "    \n",
    "    doc = nlp(query)\n",
    "    \n",
    "    ontoClasses = []\n",
    "    predicates = []\n",
    "    validClassPredicates = {}\n",
    "    offset2Class = {}\n",
    "    for ent in doc.ents:\n",
    "       \n",
    "        predicateScores = getPredicates(ent.text, topK=1)\n",
    "        pScore = list(predicateScores.values())[0][1]\n",
    "        classScores = getClasses(ent.text, topK=1)\n",
    "        cScore = list(classScores.values())[0][1]\n",
    "        if cScore >= pScore:\n",
    "            ontoClasses += [ent]\n",
    "            for token in ent:\n",
    "                offset2Class[token.i] = ent\n",
    "        else:\n",
    "            predicates += [ent]\n",
    "    \n",
    "    if len(ontoClasses) == 0: \n",
    "        ontoClasses = [doc]\n",
    "            \n",
    "    # check the entities describe by predicate (usually predicate's child)\n",
    "    for ent in predicates:\n",
    "        for token in ent:\n",
    "            for child in token.children:\n",
    "                if child.i in offset2Class:\n",
    "                    idx = ontoClasses.index(offset2Class[child.i])\n",
    "                    if idx not in validClassPredicates:\n",
    "                        validClassPredicates[idx] = [ent]\n",
    "                    else:\n",
    "                        validClassPredicates[idx] += [ent]\n",
    "                    break # only consider the closest class. remove break if considering all classes\n",
    "    \n",
    "    classEmbeddings = []\n",
    "    for i in range(len(ontoClasses)):\n",
    "        classEmbedding = sbert.encode(ontoClasses[i].text, convert_to_tensor=True)\n",
    "        if i in validClassPredicates:\n",
    "            predicateEmbeddings = [sbert.encode(ent.text, convert_to_tensor=True) for ent in validClassPredicates[i]]\n",
    "            pathEmbedding = torch.mean(torch.stack(predicateEmbeddings, dim=0), dim=0)\n",
    "            classEmbedding = torch.mean(torch.stack([classEmbedding, pathEmbedding], dim=0), dim=0)\n",
    "        classEmbeddings += [classEmbedding]\n",
    "    textEmbedding = torch.mean(torch.stack(classEmbeddings, dim=0), dim=0)      \n",
    "        \n",
    "    ### Get global query embedding\n",
    "    textEmbeddingGlobal = sbert.encode(query, convert_to_tensor=True)\n",
    "    ### Combine global and local embedding\n",
    "    textEmbedding = torch.mean(torch.stack([textEmbeddingGlobal, textEmbedding], dim=0), dim=0)       \n",
    "    \n",
    "    # We use cosine-similarity and torch.topk to find the highest top_k scores\n",
    "    bestType = classifyQuery(modelClassifier, query)\n",
    "    if bestType == 0:\n",
    "        cosScores = util.pytorch_cos_sim(textEmbedding, entityEmbedding['class'])[0]\n",
    "    else:\n",
    "        cosScores = util.pytorch_cos_sim(textEmbedding, entityEmbedding['class_predicate'])[0]\n",
    "    \n",
    "    topResults = torch.topk(cosScores, k=topK)\n",
    "    entities = {}\n",
    "    varIds = list(entityKeys.keys())\n",
    "    for rank, (score, idx) in enumerate(zip(topResults[0], topResults[1])):\n",
    "        entities[varIds[idx]] = [rank, score.item(), entityKeys[varIds[idx]]]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a07d31",
   "metadata": {},
   "source": [
    "### Now check for TF-IDF BM-25, for based comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def camel_case_split(identifier):\n",
    "    matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
    "    return [m.group(0) for m in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a307d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### organised variable text as a plain text then store it into dataframe\n",
    "\n",
    "# loop for each variable\n",
    "varTexts = {'varId':[], 'name':[], 'name_synonym':[], 'name_synonym_def':[], 'name_synonym_predicate':[]}\n",
    "for varId, value in variables['data'].items():\n",
    "    \n",
    "    names = []\n",
    "    synonyms = []\n",
    "    definitions = []\n",
    "    predicates = []\n",
    "    if 'rdfLeaves' in value:\n",
    "        for leaf in value['rdfLeaves']:\n",
    "            leaf = str(leaf).strip()\n",
    "            # get ontology class para\n",
    "            if leaf.startswith('http'):\n",
    "                classId = leaf.rsplit('/',1)[-1].rsplit('#',1)[-1].replace('_',':')\n",
    "            elif leaf.startswith('urn:miriam'):\n",
    "                classId = leaf.rsplit(':',1)[-1].replace('%3A',':')\n",
    "            if leaf.startswith('http') or leaf.startswith('urn:miriam'):\n",
    "                textFeature = getClassText(classId, features=['name', 'synonym', 'def'])\n",
    "                if len(textFeature)==0: continue\n",
    "                names += [textFeature['name']]\n",
    "                synonyms += ['' if not isinstance(textFeature['synonym'], str) else textFeature['synonym']]\n",
    "                definitions += ['' if not isinstance(textFeature['def'], str) else textFeature['def']]\n",
    "                predicates += [' '.join([' '.join(camel_case_split(p)).lower() for ps in entityKeys[varId]['classes'][classId]['path'] for p in ps])]\n",
    "    if len(names)==0: continue\n",
    "    varTexts['varId'] += [varId]\n",
    "    varTexts['name'] += [', '.join(set(names))]\n",
    "    varTexts['name_synonym'] += [', '.join(set(names + synonyms))]\n",
    "    varTexts['name_synonym_def'] += [', '.join(set(names + synonyms + definitions))]\n",
    "    varTexts['name_synonym_predicate'] += [', '.join(set(names + synonyms + predicates))]\n",
    "\n",
    "dfVarTexts = pd.DataFrame(varTexts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Implementation of OKapi BM25 with sklearn's TfidfVectorizer\n",
    "Distributed as CC-0 (https://creativecommons.org/publicdomain/zero/1.0/)\n",
    "\"\"\"\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "class BM25(object):\n",
    "    def __init__(self, b=0.75, k1=1.6):\n",
    "        self.vectorizer = TfidfVectorizer(norm=None, smooth_idf=False)\n",
    "        self.b = b\n",
    "        self.k1 = k1\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\" Fit IDF to documents X \"\"\"\n",
    "        self.vectorizer.fit(X)\n",
    "        y = super(TfidfVectorizer, self.vectorizer).transform(X)\n",
    "        self.avdl = y.sum(1).mean()\n",
    "\n",
    "    def transform(self, q, X):\n",
    "        \"\"\" Calculate BM25 between query q and documents X \"\"\"\n",
    "        b, k1, avdl = self.b, self.k1, self.avdl\n",
    "\n",
    "        # apply CountVectorizer\n",
    "        X = super(TfidfVectorizer, self.vectorizer).transform(X)\n",
    "        len_X = X.sum(1).A1\n",
    "        q, = super(TfidfVectorizer, self.vectorizer).transform([q])\n",
    "        assert sparse.isspmatrix_csr(q)\n",
    "\n",
    "        # convert to csc for better column slicing\n",
    "        X = X.tocsc()[:, q.indices]\n",
    "        denom = X + (k1 * (1 - b + b * len_X / avdl))[:, None]\n",
    "        # idf(t) = log [ n / df(t) ] + 1 in sklearn, so it need to be coneverted\n",
    "        # to idf(t) = log [ n / df(t) ] with minus 1\n",
    "        idf = self.vectorizer._tfidf.idf_[None, q.indices] - 1.\n",
    "        numer = X.multiply(np.broadcast_to(idf, X.shape)) * (k1 + 1)                                                          \n",
    "        return (numer / denom).sum(1).A1\n",
    "\n",
    "\n",
    "\n",
    "#------------ End of library impl. Followings are the example -----------------\n",
    "bm25 = {}\n",
    "for col in dfVarTexts.columns[1:]:\n",
    "    bm25[col] = BM25()\n",
    "    bm25[col].fit(dfVarTexts[col])\n",
    "    \n",
    "\n",
    "def entitySearchBM25(query, topK=20, indexType='name_synonym', pathType='single', minSim=0):\n",
    "    \"\"\"\n",
    "    In this approach:\n",
    "    Simply using bag of word method BM25\n",
    "    \"\"\"\n",
    "    results = bm25[indexType].transform(query, dfVarTexts[indexType])\n",
    "\n",
    "    sortedResults = {}\n",
    "    for i in results.argsort()[-topK:][::-1]:\n",
    "        sortedResults[dfVarTexts.iloc[i,0]] = (results[i], dfVarTexts.iloc[i,1])\n",
    "        \n",
    "    return sortedResults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68abdf9",
   "metadata": {},
   "source": [
    "## Now run to measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf831b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'noPredicate':{}, 'withPredicate':{}, 'combine':{}}\n",
    "topK = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetType = 'noPredicate'\n",
    "querySet = queryTest[dataSetType]['2']\n",
    "results[dataSetType]['macro'] = getMAP(querySet, entitySearch, topK=topK, indexType='class')\n",
    "results[dataSetType]['macroWP'] = getMAP(querySet, entitySearch, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['micro'] = getMAP(querySet, entitySearchClass, topK=topK, indexType='class')\n",
    "results[dataSetType]['microWP'] = getMAP(querySet, entitySearchClass, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['mixed'] = getMAP(querySet, entitySearchCombine, topK=topK, indexType='class')\n",
    "results[dataSetType]['mixedWP'] = getMAP(querySet, entitySearchCombine, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['mixedCl'] = getMAP(querySet, entitySearchCombine2, topK=topK)\n",
    "results[dataSetType]['BM25'] = getMAP(querySet, entitySearchBM25, topK=topK, indexType='name_synonym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1567e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetType = 'withPredicate'\n",
    "querySet = queryTest[dataSetType]['2']\n",
    "results[dataSetType]['macro'] = getMAP(querySet, entitySearch, topK=topK, indexType='class')\n",
    "results[dataSetType]['macroWP'] = getMAP(querySet, entitySearch, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['micro'] = getMAP(querySet, entitySearchClass, topK=topK, indexType='class')\n",
    "results[dataSetType]['microWP'] = getMAP(querySet, entitySearchClass, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['mixed'] = getMAP(querySet, entitySearchCombine, topK=topK, indexType='class')\n",
    "results[dataSetType]['mixedWP'] = getMAP(querySet, entitySearchCombine, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['mixedCl'] = getMAP(querySet, entitySearchCombine2, topK=topK)\n",
    "results[dataSetType]['BM25'] = getMAP(querySet, entitySearchBM25, topK=topK, indexType='name_synonym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc81b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetType = 'combine'\n",
    "querySet = queryTest[dataSetType]\n",
    "results[dataSetType]['macro'] = getMAP(querySet, entitySearch, topK=topK, indexType='class')\n",
    "results[dataSetType]['macroWP'] = getMAP(querySet, entitySearch, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['micro'] = getMAP(querySet, entitySearchClass, topK=topK, indexType='class')\n",
    "results[dataSetType]['microWP'] = getMAP(querySet, entitySearchClass, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['mixed'] = getMAP(querySet, entitySearchCombine, topK=topK, indexType='class')\n",
    "results[dataSetType]['mixedWP'] = getMAP(querySet, entitySearchCombine, topK=topK, indexType='class_predicate')\n",
    "results[dataSetType]['mixedCl'] = getMAP(querySet, entitySearchCombine2, topK=topK)\n",
    "results[dataSetType]['BM25'] = getMAP(querySet, entitySearchBM25, topK=topK, indexType='name_synonym')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2c294",
   "metadata": {},
   "source": [
    "### Analysis result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e91287",
   "metadata": {},
   "outputs": [],
   "source": [
    "globalResults = {'approach':[], 'noPredicate_MAP':[], 'noPredicate_MRR':[], 'withPredicate_MAP':[], 'withPredicate_MRR':[], 'combine_MAP':[], 'combine_MRR':[]}\n",
    "\n",
    "for approach in list(results.values())[0].keys():\n",
    "    globalResults['approach'] += [approach]\n",
    "    for dataType, v in results.items():\n",
    "        globalResults[dataType+'_MAP'] += [v[approach]['MAP']['score']]\n",
    "        globalResults[dataType+'_MRR'] += [v[approach]['MRR']['score']]\n",
    "\n",
    "df_globalResults = pd.DataFrame(globalResults)\n",
    "df_globalResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b92d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateQueryEntityScore(qTest):\n",
    "    for query,v in tqdm(qTest.items()):\n",
    "        pos = entityKeys[v['vars'][0]]['pos']\n",
    "        queryEmb = sbert.encode(query, convert_to_tensor=True)\n",
    "        entityEmb = entityEmbedding['class'][pos]\n",
    "        cosScore = util.pytorch_cos_sim(entityEmb, queryEmb)\n",
    "        v['score']  = cosScore.item()\n",
    "        \n",
    "updateQueryEntityScore(queryTest['noPredicate']['0'])\n",
    "updateQueryEntityScore(queryTest['noPredicate']['1'])\n",
    "updateQueryEntityScore(queryTest['noPredicate']['2'])\n",
    "updateQueryEntityScore(queryTest['withPredicate']['0'])\n",
    "updateQueryEntityScore(queryTest['withPredicate']['1'])\n",
    "updateQueryEntityScore(queryTest['withPredicate']['2'])\n",
    "updateQueryEntityScore(queryTest['combine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailResults = {'approach':[], 'dataType':[], 'query_Class_Sim':[], 'MAP':[], 'MRR':[]}\n",
    "queryReference = {'noPredicate':[v['score'] for k,v in queryTest['noPredicate']['2'].items()], \n",
    "                  'withPredicate':[v['score'] for k,v in queryTest['withPredicate']['2'].items()], \n",
    "                  'combine':[v['score'] for k,v in queryTest['combine'].items()]} \n",
    "\n",
    "for approach in list(results.values())[0].keys():\n",
    "    for dataType, v in results.items():\n",
    "        for a,b,c in zip(queryReference[dataType], list(v[approach]['MAP']['stat'].values()), list(v[approach]['MRR']['stat'].values())):\n",
    "            detailResults['approach'] += [approach]\n",
    "            detailResults['dataType'] += [dataType]\n",
    "            detailResults['query_Class_Sim'] += [a]\n",
    "            detailResults['MAP'] += [b]\n",
    "            detailResults['MRR'] += [c]\n",
    "\n",
    "        \n",
    "#         detailResults[dataType+'_MAP'] += [v[approach]['MAP']['score']]\n",
    "#         detailResults[dataType+'_MRR'] += [v[approach]['MRR']['score']]\n",
    "\n",
    "df_detailResults = pd.DataFrame(detailResults)\n",
    "df_detailResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e0579f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfPlot = df_detailResults[df_detailResults['dataType']=='combine']\n",
    "dfPlot.query_Class_Sim = np.floor(dfPlot.query_Class_Sim*10)/10\n",
    "dfPlot.loc[(dfPlot.query_Class_Sim == 1.0),'query_Class_Sim']=0.9\n",
    "\n",
    "dfPlot.query_Class_Sim = dfPlot.query_Class_Sim.astype(str)+'-'+(dfPlot.query_Class_Sim+0.1).round(1).astype(str)\n",
    "# dfPlot = dfPlot.groupby(['approach', 'query_Class_Sim'], as_index=False)['MAP', 'MRR'].mean()\n",
    "dfPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ax = sns.lineplot(x = \"query_Class_Sim\", y = \"MAP\", hue=\"approach\", data = dfPlot)\n",
    "order = dfPlot['query_Class_Sim'].unique().tolist()\n",
    "order.sort()\n",
    "ax = sns.factorplot(x = \"query_Class_Sim\", y = \"MAP\", hue=\"approach\", data = dfPlot, order=order, legend=False)\n",
    "ax.despine(left=True)\n",
    "plt.legend(loc='right')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches( 10, 8)\n",
    "ax.set(xlabel=\"'Query - Entity's Terms' Similarity\", ylabel=\"mAP@10\")\n",
    "\n",
    "counts = tuple((100.*dfPlot.groupby('query_Class_Sim').count()['approach']/dfPlot.shape[0]).round(1).astype(str)+'%')\n",
    "print(counts)\n",
    "for i, c in enumerate(counts):\n",
    "    pos= (i*0.91, 0.2+i*0.1) if c not in counts[-3:] else (i*0.95, 1)\n",
    "    plt.annotate(c, xy = pos, \n",
    "             fontsize = 8, xytext = pos, \n",
    "             color = 'g')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70486a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('casbert_results/pmr_results.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac65c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
